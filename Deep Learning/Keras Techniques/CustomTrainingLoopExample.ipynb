{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfb4458-5e97-4656-8397-fde19cdd71f6",
   "metadata": {},
   "source": [
    "# Custom Training Loops in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d897b-21d8-4cd5-93f9-74e7f0fdd1a3",
   "metadata": {},
   "source": [
    "- Environment set up\n",
    "- Define neural network model \n",
    "- Define Loss Function and Optimizer\n",
    "- Implement the custom training loop\n",
    "- Enhance the custom training loop by adding an accuracy metric to monitor model performance\n",
    "- Implement a custom callback to log additional metrics and information during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16404247-9873-47bf-88fe-870c87905620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting visualkeras\n",
      "  Downloading visualkeras-0.1.4-py3-none-any.whl (17 kB)\n",
      "Collecting aggdraw>=1.3.11\n",
      "  Downloading aggdraw-1.3.19-cp39-cp39-macosx_14_0_arm64.whl (479 kB)\n",
      "\u001b[K     |████████████████████████████████| 479 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from visualkeras) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from visualkeras) (2.0.2)\n",
      "Installing collected packages: aggdraw, visualkeras\n",
      "Successfully installed aggdraw-1.3.19 visualkeras-0.1.4\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248f62cb-6da7-4811-b422-99a4dcd82a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (2.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "379466e4-caca-4b37-92b0-59958555fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import visualkeras\n",
    "import numpy as np\n",
    "\n",
    "# Suppress all Python warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set TensorFlow log level to suppress warnings and info messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "\n",
    "# Use only a subset of MNIST data for faster processing\n",
    "x_train = x_train[:5000]  # Only first 5000 samples\n",
    "y_train = y_train[:5000]\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "\n",
    "# Create a batched dataset for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7d7dd98-d01c-4bce-a224-a067183828d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=595x65>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a simple neural network model with a flatten layer followed by two dense layers\n",
    "#This step defines the model\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])\n",
    "\n",
    "# Visualize with VisualKeras\n",
    "visualkeras.layered_view(model, legend=True, scale_xy=3, scale_z=1, to_file='model_viz.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "796fc4ce-35c4-42b4-a3ba-0759e29196bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function and Optimizer\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()  # Metric to track accuracy during training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259fa6d-77e4-49c3-9247-7c1058ac3663",
   "metadata": {},
   "source": [
    "## The next steps deal with how to implement a custom training loop in Keras that iterates over a dataset for n number of epochs, computes the loss and applies gradients to update the model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f28d73b3-8394-462a-b498-86435a77a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 5.9334575780667365e-05 Accuracy = 1.0\n",
      "End of epoch 1, loss: 0.0, accuracy: 1.0\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 5.336182584869675e-05 Accuracy = 1.0\n",
      "End of epoch 2, loss: 0.0, accuracy: 1.0\n",
      "Start of epoch 3\n",
      "Epoch 3 Step 0: Loss = 4.7756187996128574e-05 Accuracy = 1.0\n",
      "End of epoch 3, loss: 0.0, accuracy: 1.0\n",
      "Start of epoch 4\n",
      "Epoch 4 Step 0: Loss = 4.341456588008441e-05 Accuracy = 1.0\n",
      "End of epoch 4, loss: 0.0, accuracy: 1.0\n",
      "Start of epoch 5\n",
      "Epoch 5 Step 0: Loss = 3.959703099098988e-05 Accuracy = 1.0\n",
      "End of epoch 5, loss: 0.0, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Custom training loop\n",
    "epochs = 5  # Number of epochs for training\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        print(f'End of epoch {epoch + 1}, loss: {logs.get(\"loss\")}, accuracy: {logs.get(\"accuracy\")}')\n",
    "\n",
    "epochs = 5\n",
    "custom_callback = CustomCallback()  # Initialize the custom callback\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # Apply gradients to update model weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update the accuracy metric\n",
    "        accuracy_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log the loss and accuracy every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()} Accuracy = {accuracy_metric.result().numpy()}')\n",
    "    \n",
    "    # Call the custom callback at the end of each epoch\n",
    "    custom_callback.on_epoch_end(epoch, logs={'loss': loss_value.numpy(), 'accuracy': accuracy_metric.result().numpy()})\n",
    "    \n",
    "    # Reset the metric at the end of each epoch\n",
    "    accuracy_metric.reset_state()  # Use reset_state() instead of reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6864d-3f0e-4a2a-a451-935563173eaf",
   "metadata": {},
   "source": [
    "# Custom Training Loop Summary\n",
    "\n",
    "## What This Demonstrates\n",
    "This notebook demonstrates a manual implementation of neural network training using the advanced Keras custom training loop with `GradientTape` instead of the standard `model.fit()`. This shows how to incorporate low-level control over forward passes, gradient computation, weight updates, and metrics tracking.\n",
    "\n",
    "## When to Use\n",
    "- **Research/experimentation** needing fine control over training\n",
    "- **Complex scenarios**: GANs, custom losses, multi-model training\n",
    "- **Learning/debugging** training mechanics\n",
    "\n",
    "For standard tasks, you can use Keras's standard `model.fit()` \n",
    "\n",
    "## Results\n",
    "Loss decreased from 5.9e-5 to 3.9e-5 with 100% accuracy throughout training. This indicates the model quickly learned the MNIST digit patterns from the 5,000 sample subset. The extremely low loss and perfect accuracy suggest the task was well within the model's capacity - typical for MNIST with sufficient training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022aa5f-8b35-4ff7-91d7-5a6b038cb90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
