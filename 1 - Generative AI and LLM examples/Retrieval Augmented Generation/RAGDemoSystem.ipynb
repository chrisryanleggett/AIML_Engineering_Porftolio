{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31430b6-3830-4c6e-831d-ef6d43cb9b4a",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4567c2-db92-46cc-a395-4997e251a2e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Summary: RAG Document Q&A System\n",
    "\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) system for querying ACME Medical Devices corporate documents.\n",
    "\n",
    "### Test Data\n",
    "\n",
    "**Location:** `RAGSystemInputDocs/`\n",
    "\n",
    "**Purpose:** Synthetic corporate documents created for verification and demonstration purposes. This test data was used to run the flows and prove the RAG pipeline works end-to-end.\n",
    "\n",
    "**Documents:** 8 corporate procedure PDFs covering:\n",
    "- Sales Team (pricing authority, anti-kickback rules)\n",
    "- Manufacturing Team (DHR requirements, non-conformance handling, cleanroom protocols)\n",
    "- Product Team (launch gate reviews, design controls)\n",
    "- Customer Support (complaint classification tiers, escalation procedures)\n",
    "- Medical Partnerships (KOL contracts, Sunshine Act compliance)\n",
    "- Accounting (expense thresholds, SOX controls)\n",
    "- Legal (contract authority, litigation holds)\n",
    "- Regulatory Affairs (510(k) requirements, MDR deadlines)\n",
    "\n",
    "Each document contains team leadership contacts, mandatory rules, required approvals, and escalation procedures for legal gray areas.\n",
    "\n",
    "### Architecture & Flow\n",
    "\n",
    "| Step | Component | Purpose |\n",
    "|------|-----------|---------|\n",
    "| 1 | **Tokenizer** (AutoTokenizer) | Converts text into token IDs for model processing |\n",
    "| 2 | **Context Encoder** (DPRContextEncoder) | Converts documents into vector embeddings |\n",
    "| 3 | **Document Loader** (PyPDFLoader + TextSplitter) | Loads and chunks PDFs for processing |\n",
    "| 4 | **Embedding Generation** | Encodes all document chunks into vectors |\n",
    "| 5 | **Vector Index** (FAISS) | Stores embeddings for fast similarity search |\n",
    "| 6 | **Question Encoder** (DPRQuestionEncoder) | Encodes user questions for comparison |\n",
    "| 7 | **Search Function** | Finds most relevant document chunks for a query |\n",
    "| 8 | **LLM Integration** (Claude API) | Generates conversational answers from retrieved context |\n",
    "\n",
    "### Query Flow\n",
    "```\n",
    "User Question → Question Encoder → FAISS Search → Top-k Chunks → Claude Prompt → Answer\n",
    "```\n",
    "\n",
    "### Limitations & Areas for Future Improvement\n",
    "\n",
    "| Limitation | Improvement |\n",
    "|------------|-------------|\n",
    "| Fixed chunk size/overlap may not suit varied document types | Use LangChain's SemanticChunker or implement parent-child retrieval |\n",
    "| DPR model not trained on domain terminology | Fine-tune embeddings or use domain-specific models |\n",
    "| High k value needed for reliable retrieval | Better embedding models (e.g., OpenAI ada-002, Cohere) |\n",
    "| No persistence — index rebuilds each run | Save FAISS index to disk, add vector database (Pinecone, Chroma) |\n",
    "| Small dataset | Scale testing with larger document sets |\n",
    "| No reranking | Add cross-encoder reranker for improved precision |\n",
    "\n",
    "### Usage\n",
    "\n",
    "**For developers adapting this code:**\n",
    "\n",
    "1. Replace `RAGSystemInputDocs/` with your own PDF documents\n",
    "2. Replace references to`ANTHROPIC_API_KEY` with your real API key\n",
    "3. Adjust `chunk_size` and `chunk_overlap` based on your document structure\n",
    "4. Tune `k` based on your total chunk count\n",
    "5. Modify the prompt template in `ask_acme()` to fit your domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e996739-6129-4f9e-9267-d6e3001ac5ce",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ccf7cea-3bc1-4b78-be48-5eeec53b7ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer load details (printed for verification):\n",
      "Tokenizer type: <class 'transformers.models.dpr.tokenization_dpr_fast.DPRQuestionEncoderTokenizerFast'>\n",
      "Vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"urllib3\")\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "#Import context tokenizer\n",
    "from transformers import DPRContextEncoderTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#Load pre-trained tokenizer to enable tokenization of input context documents\n",
    "model_name = 'facebook/dpr-ctx_encoder-single-nq-base'\n",
    "context_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Verify it loaded\n",
    "print(\"Tokenizer load details (printed for verification):\")\n",
    "print(f\"Tokenizer type: {type(context_tokenizer)}\")\n",
    "print(f\"Vocab size: {context_tokenizer.vocab_size}\")\n",
    "\n",
    "#Initialize the Context encoder\n",
    "from transformers import DPRContextEncoder\n",
    "encoder_model = 'facebook/dpr-ctx_encoder-single-nq-base'\n",
    "context_encoder = DPRContextEncoder.from_pretrained(encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abf07868-d7cf-4bc0-b555-23f1c172c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-enable warnings for this section\n",
    "from transformers import logging\n",
    "logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca852a-4944-43fd-9016-328c038be78d",
   "metadata": {},
   "source": [
    "## Install LangChain pyPDF for PDF processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98ec9d94-2ca9-4fc4-b05d-68cd7d62fc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (0.3.27)\n",
      "Requirement already satisfied: pypdf in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (6.5.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.81)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain) (0.4.37)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.45)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-community in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.3.81)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.0.45)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.4.37)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "!pip3 install langchain pypdf #You can skip this line if already installed in your environment or replace with appropriate install command\n",
    "!pip3 install langchain-community\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f85c8-f979-472f-9ea8-294eb571439c",
   "metadata": {},
   "source": [
    "## Loading the test dataset for ACMEMedicalDevicesCompany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b4c7afb6-a32d-43e5-876e-01cb13ba9605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 text chunks from PDFs\n"
     ]
    }
   ],
   "source": [
    "doc_folder = \"RAGSystemInputDocs\"\n",
    "all_paragraphs = []\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=300,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
    ")\n",
    "\n",
    "for filename in os.listdir(doc_folder):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(os.path.join(doc_folder, filename))\n",
    "        pages = loader.load()\n",
    "        for page in pages:\n",
    "            text = page.page_content.replace(\"  \", \" \")\n",
    "            chunks = text_splitter.split_text(text)\n",
    "            all_paragraphs.extend(chunks)\n",
    "\n",
    "print(f\"Loaded {len(all_paragraphs)} text chunks from PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efff197-c21b-401d-bf05-31354b4bac07",
   "metadata": {},
   "source": [
    "## Convert text chunks from documents into searchable vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "facd1d20-61b9-4b1d-8218-e1d78febf115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context embeddings shape: torch.Size([24, 768])\n",
      "  → 24 document chunks\n",
      "  → 768 dimensions per embedding\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Encode all document chunks into embeddings\n",
    "embeddings = []\n",
    "for chunk in all_paragraphs:\n",
    "    tokens = context_tokenizer(chunk, return_tensors='pt', truncation=True, max_length=256, padding=True)\n",
    "    with torch.no_grad():\n",
    "        embedding = context_encoder(**tokens).pooler_output\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "embeddings_tensor = torch.cat(embeddings, dim=0)\n",
    "\n",
    "# Verify embeddings shape\n",
    "print(f\"Context embeddings shape: {embeddings_tensor.shape}\")\n",
    "print(f\"  → {embeddings_tensor.shape[0]} document chunks\")\n",
    "print(f\"  → {embeddings_tensor.shape[1]} dimensions per embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf595e20-7617-47f4-a3d2-23ac8765dcdc",
   "metadata": {},
   "source": [
    "## Implement Facebook AI Similarity Search (Faiss)\n",
    "* Selected Faiss (developed by FAIR) for efficient searching and processing of collections of high-dimensional vectors.\n",
    "* FAISS will find the k most similar vectors to a query vector from a large collection using distance metrics. When a user asks a question, FAISS searches our document embeddings and returns the most relevant chunks to answer it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9636e862-8887-45a9-8c60-3722d59f57f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from faiss-cpu) (25.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install faiss-cpu\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4223ce25-a3ef-4fcb-9bdb-ce5b23c3b93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 24 vectors of 768 dimensions\n"
     ]
    }
   ],
   "source": [
    "context_embeddings_np = embeddings_tensor.detach().numpy().astype('float32')\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings_tensor.shape[1])\n",
    "index.add(context_embeddings_np)\n",
    "\n",
    "print(f\"FAISS index created with {index.ntotal} vectors of {embeddings_tensor.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55dc1f72-81d9-449e-b20d-cfcd7b22bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question encoder loaded: <class 'transformers.models.dpr.modeling_dpr.DPRQuestionEncoder'>\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings in this cell\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Implement the question encoder\n",
    "from transformers import DPRQuestionEncoder\n",
    "\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "question_tokenizer = AutoTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "print(f\"Question encoder loaded: {type(question_encoder)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6bcbe917-f82c-49b4-8155-6c0284b1b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to encode a question into an embedding for FAISS comparison\n",
    "def search(question, k=3):\n",
    "    # Encode the question\n",
    "    tokens = question_tokenizer(question, return_tensors='pt', truncation=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        question_embedding = question_encoder(**tokens).pooler_output.numpy().astype('float32')\n",
    "    \n",
    "    # Search FAISS index\n",
    "    distances, indices = index.search(question_embedding, k)\n",
    "    \n",
    "    # Return top k matching chunks\n",
    "    return [(all_paragraphs[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
    "\n",
    "# Define a search function takes a user question, encodes it, and returns the k most relevant document chunks\n",
    "def search(question, k=3):\n",
    "    tokens = question_tokenizer(question, return_tensors='pt', truncation=True, max_length=256)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_embedding = question_encoder(**tokens).pooler_output.numpy().astype('float32')\n",
    "    \n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    results = []\n",
    "    for j, i in enumerate(indices[0]):\n",
    "        results.append((all_paragraphs[i], distances[0][j]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfe8bfde-bcc6-44aa-ac91-edd7763a3c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: anthropic in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (0.64.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anthropic) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anthropic) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anthropic) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f143e408-ec24-471d-a1cb-f6a13470bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API connection success!\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Replace with your own API key\n",
    "# Locally I chose to load my API key from .env file, but you can provide your own implementation to make Claude connection here\n",
    "load_dotenv()\n",
    "CLAUDE_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "client = Anthropic(api_key=CLAUDE_API_KEY)\n",
    "\n",
    "# Test API connection\n",
    "try:\n",
    "    test_response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=10,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hi\"}]\n",
    "    )\n",
    "    print(\"API connection success!\")\n",
    "except Exception as e:\n",
    "    print(f\"API connection failed\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0083341b-94c7-4ac9-8f9d-701f7a412474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITION FOR INTERACTIVE Q&A DEMO\n",
    "\n",
    "def ask_acme(question, k=15): #Increasing k will consume more tokens and lead to slower responses but retrieves more relevant chunks that DPR ranks poorly due to terminology mismatch\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"STEP 1: User Question\")\n",
    "    print(f\"  → {question}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"STEP 2: Searching FAISS index for top {k} relevant chunks...\")\n",
    "    chunks = search(question, k)\n",
    "    print(f\"  → Retrieved {len(chunks)} chunks (distances: {[f'{d:.1f}' for _, d in chunks]})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 3: Building prompt with retrieved context...\")\n",
    "    context = \"\\n\\n\".join([chunk[0] for chunk in chunks])\n",
    "    prompt = f\"\"\"Based on the following ACME Medical Devices company documents, answer the question. \n",
    "Be concise and specific. If the answer isn't in the context, say so.\n",
    "Context:\n",
    "{context}\n",
    "Question: {question}\"\"\"\n",
    "    print(f\"  → Prompt built with {len(context)} characters of context\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 4: Sending to Claude for conversational response...\")\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=500,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    answer = response.content[0].text\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 5: Final Answer\")\n",
    "    print(f\"\\n{answer}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146b0a9-d8cf-409c-8292-70c2eb0d1d64",
   "metadata": {},
   "source": [
    "# Putting it All Together: Interactive RAG Demo, Document Q&A with FAISS Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a960065d-6b00-476d-81f3-ef50b2f17176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about ACME Medical Devices (or 'quit' to exit):  What are the Device History Record requirements?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: User Question\n",
      "  → What are the Device History Record requirements?\n",
      "\n",
      "============================================================\n",
      "STEP 2: Searching FAISS index for top 15 relevant chunks...\n",
      "  → Retrieved 15 chunks (distances: ['100.8', '101.4', '101.8', '103.0', '103.6', '104.2', '104.6', '104.7', '104.8', '105.6', '105.9', '106.0', '106.3', '107.4', '107.8'])\n",
      "\n",
      "============================================================\n",
      "STEP 3: Building prompt with retrieved context...\n",
      "  → Prompt built with 15324 characters of context\n",
      "\n",
      "============================================================\n",
      "STEP 4: Sending to Claude for conversational response...\n",
      "\n",
      "============================================================\n",
      "STEP 5: Final Answer\n",
      "\n",
      "Based on the ACME Medical Devices Manufacturing Team operating procedures, the Device History Record (DHR) requirements are:\n",
      "\n",
      "**Mandatory Requirements:**\n",
      "- Every device MUST have a complete DHR before release\n",
      "- DHR must include: lot numbers, component traceability, test results, and operator IDs\n",
      "- Missing DHR data = STOP SHIPMENT until resolved\n",
      "- DHR falsification = immediate termination and FDA notification\n",
      "\n",
      "These requirements fall under the Manufacturing Team's mandatory rules and are part of compliance with FDA 21 CFR Part 820 Quality System Regulation and ISO 13485:2016 requirements.\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about ACME Medical Devices (or 'quit' to exit):  Who is the VP of Regulatory Affairs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: User Question\n",
      "  → Who is the VP of Regulatory Affairs?\n",
      "\n",
      "============================================================\n",
      "STEP 2: Searching FAISS index for top 15 relevant chunks...\n",
      "  → Retrieved 15 chunks (distances: ['102.9', '103.7', '104.5', '105.1', '106.0', '106.3', '107.6', '108.6', '109.8', '114.6', '114.8', '114.8', '115.0', '115.9', '116.3'])\n",
      "\n",
      "============================================================\n",
      "STEP 3: Building prompt with retrieved context...\n",
      "  → Prompt built with 16597 characters of context\n",
      "\n",
      "============================================================\n",
      "STEP 4: Sending to Claude for conversational response...\n",
      "\n",
      "============================================================\n",
      "STEP 5: Final Answer\n",
      "\n",
      "Based on the documents provided, the VP of Regulatory Affairs is **Dr. Robert Kim** (contact: rkim@acmemeddevices.com).\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about ACME Medical Devices (or 'quit' to exit):  What are the labeling change requirements?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: User Question\n",
      "  → What are the labeling change requirements?\n",
      "\n",
      "============================================================\n",
      "STEP 2: Searching FAISS index for top 15 relevant chunks...\n",
      "  → Retrieved 15 chunks (distances: ['98.2', '101.7', '101.9', '109.7', '109.8', '109.9', '110.6', '111.6', '113.1', '114.3', '115.5', '117.1', '118.4', '118.9', '118.9'])\n",
      "\n",
      "============================================================\n",
      "STEP 3: Building prompt with retrieved context...\n",
      "  → Prompt built with 13527 characters of context\n",
      "\n",
      "============================================================\n",
      "STEP 4: Sending to Claude for conversational response...\n",
      "\n",
      "============================================================\n",
      "STEP 5: Final Answer\n",
      "\n",
      "Based on the ACME Medical Devices documents, the labeling change requirements are:\n",
      "\n",
      "**Mandatory Requirements:**\n",
      "- **ANY labeling change requires RA (Regulatory Affairs) review before implementation**\n",
      "- **Approver:** VP RA must approve all label changes\n",
      "- **Form:** ACME-LBL-001 form must be used\n",
      "\n",
      "**Key Considerations:**\n",
      "- **IFU (Instructions for Use) changes may trigger new 510(k)** - always consult RA first\n",
      "- **UDI compliance required for all Class II devices**\n",
      "\n",
      "The documents emphasize that no labeling changes can be implemented without prior Regulatory Affairs review and VP RA approval.\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about ACME Medical Devices (or 'quit' to exit):  What should I do if a customer threatens a lawsuit?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: User Question\n",
      "  → What should I do if a customer threatens a lawsuit?\n",
      "\n",
      "============================================================\n",
      "STEP 2: Searching FAISS index for top 15 relevant chunks...\n",
      "  → Retrieved 15 chunks (distances: ['109.7', '111.0', '111.5', '111.7', '112.8', '113.1', '114.2', '116.0', '118.2', '119.2', '120.0', '121.2', '122.0', '122.5', '122.5'])\n",
      "\n",
      "============================================================\n",
      "STEP 3: Building prompt with retrieved context...\n",
      "  → Prompt built with 15185 characters of context\n",
      "\n",
      "============================================================\n",
      "STEP 4: Sending to Claude for conversational response...\n",
      "\n",
      "============================================================\n",
      "STEP 5: Final Answer\n",
      "\n",
      "Based on the ACME Medical Devices documents, if a customer threatens a lawsuit, you should:\n",
      "\n",
      "1. **Remain calm and professional**\n",
      "2. **Do NOT apologize or admit fault**\n",
      "3. **Document verbatim** what the customer said\n",
      "4. **Escalate immediately to Legal (Angela Martinez)**\n",
      "5. **Do not contact the customer again without Legal guidance**\n",
      "\n",
      "This procedure applies specifically when a customer mentions lawsuit, attorney, or legal action during any interaction.\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about ACME Medical Devices (or 'quit' to exit):  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"\\nAsk a question about ACME Medical Devices (or 'quit' to exit): \")\n",
    "    if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    ask_acme(user_input, k=15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b2d6b-91fd-41e3-ae95-dda46feaf704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
