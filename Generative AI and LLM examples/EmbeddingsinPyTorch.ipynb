{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f09feee-c7d0-4833-a414-4fc9c6342a87",
   "metadata": {},
   "source": [
    "# Working with Embedding and EmbeddingBag in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8034be84-e22c-4d8a-96e8-8de73b30a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchtext in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (0.17.2)\n",
      "Requirement already satisfied: tqdm in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torchtext) (4.67.1)\n",
      "Requirement already satisfied: requests in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torchtext) (2.32.5)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torchtext) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torchtext) (2.0.2)\n",
      "Requirement already satisfied: filelock in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torch==2.2.2->torchtext) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torch==2.2.2->torchtext) (4.14.1)\n",
      "Requirement already satisfied: sympy in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torch==2.2.2->torchtext) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torch==2.2.2->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torch==2.2.2->torchtext) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from torch==2.2.2->torchtext) (2025.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.2.2->torchtext) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests->torchtext) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests->torchtext) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests->torchtext) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests->torchtext) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from sympy->torch==2.2.2->torchtext) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (0.17.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/christopherleggett/Library/Python/3.9/lib/python/site-packages (from jinja2->spacy) (3.0.2)\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 147, in _get_module_details\n",
      "    return _get_module_details(pkg_main_name, error)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/spacy/__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/spacy/errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/spacy/compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/thinc/__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/thinc/config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/thinc/types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/thinc/compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/christopherleggett/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install torchtext\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b13e2df5-b7bf-4583-832e-e48743ec8ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 6, 2]), tensor([0, 3, 4]), tensor([0, 1, 7, 8, 5])]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary functions\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch.nn as nn\n",
    "\n",
    "#Create a sample dataset or corpus as a set of sentences\n",
    "MyCorpus = [\n",
    "    \"I like cats\",\n",
    "    \"I dislike dogs\", \n",
    "    \"I'm neutral to hippos\"\n",
    "]\n",
    "\n",
    "#Initialize the tokenizer, iterator from the dataset and vocabulary \n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for data_sample in data_iter:\n",
    "        yield tokenizer(data_sample)\n",
    "\n",
    "data_iter = iter(MyCorpus)\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for data_sample in data_iter:\n",
    "        yield tokenizer(data_sample)\n",
    "\n",
    "# Build vocabulary using a fresh iterator\n",
    "vocab = build_vocab_from_iterator(yield_tokens(data_iter))\n",
    "\n",
    "# Tokenize and generate the data indices for each data sample \n",
    "\n",
    "#input_ids lambda function tokenizes and generates indexes for each data sample \n",
    "\n",
    "input_ids = lambda x: [torch.tensor(vocab(tokenizer(data_sample))) for data_sample in MyCorpus]\n",
    "index = input_ids(MyCorpus)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b78fd19e-7b04-4d17-b048-6c074489dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Embedding(9, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creation of the embeddings layer\n",
    "# The embedding layer in an LLM converts discrete tokens (words, subwords, or characters)\n",
    "embedding_dim = 3  #Dimension size of the embeddings\n",
    "\n",
    "#Count of unique tokens present in the vocab\n",
    "\n",
    "n_embedding = len(vocab)\n",
    "print(n_embedding)\n",
    "\n",
    "embeds = nn.Embedding(n_embedding, embedding_dim) #nn.embedding constructor to create embedding layer embeds\n",
    "print(embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071bbf93-2186-4e03-bf90-80fc82c8c9bc",
   "metadata": {},
   "source": [
    "## Explanation \n",
    "- We used the spaCy tokenizer, which splits I into I and m, resulting in a total of 9 tokens. \n",
    "- There are 9 tokens in the vocabulary because corpus tokens have tokenization are : \"I\", \"like\", \"cats\", \"dislike\", \"dogs\", \"m (from I'ms)\", \"neutral\", \"to\", \"hippos\").\n",
    "- Vocabulary size = 9\n",
    "- Embedding (9, 3) : 9 rows (1 for each token in the voculbarly), 3 columns (embedding dimension we set earlier). This creates a lookup table where each of your  tokens maps to a vector. When you pass token indices to this embedding layer, it will return the corresponding vectors that can be used by the neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55566cbc-af98-4818-b83c-0f5eaf96e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sentence embeddings:\n",
      "'I like cats' -> tensor([-0.0378, -0.2755,  0.5874], grad_fn=<UnbindBackward0>)\n",
      "'I dislike dogs' -> tensor([-1.2483,  0.1715,  0.3958], grad_fn=<UnbindBackward0>)\n",
      "'I'm neutral to hippos' -> tensor([ 0.4127, -0.2397,  0.2168], grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Batch processing approach\n",
    "index_flat = torch.cat(index)\n",
    "offset = [len(sample) for sample in index]\n",
    "offset.insert(0, 0)\n",
    "offset = torch.cumsum(torch.tensor(offset), 0)[0:-1]\n",
    "\n",
    "my_embeddings = embedding_bag(index_flat, offsets=offset)\n",
    "\n",
    "# Print all embeddings with their corresponding sentences\n",
    "print(\"All sentence embeddings:\")\n",
    "for i, embedding in enumerate(my_embeddings):\n",
    "    print(f\"'{MyCorpus[i]}' -> {embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33a74fce-86e4-44a5-8fe6-ec9a55856bca",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m    sentiment_loss \u001b[38;5;241m=\u001b[39m criterion(sentiment_pred, sentiment_labels)\n\u001b[1;32m     28\u001b[0m    total_loss \u001b[38;5;241m=\u001b[39m animal_loss \u001b[38;5;241m+\u001b[39m sentiment_loss\n\u001b[0;32m---> 30\u001b[0m    \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m    optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "animal_labels = torch.tensor([0, 1, 2])  # 0=cats, 1=dogs, 2=hippos\n",
    "sentiment_labels = torch.tensor([1, 0, 2])  # 0=dislike, 1=like, 2=neutral\n",
    "\n",
    "# Define a simple neural network\n",
    "class AnimalSentimentClassifier(nn.Module):\n",
    "   def __init__(self):\n",
    "       super().__init__()\n",
    "       self.animal_classifier = nn.Linear(3, 3)  # 3D embedding -> 3 animals\n",
    "       self.sentiment_classifier = nn.Linear(3, 3)  # 3D embedding -> 3 sentiments\n",
    "   \n",
    "   def forward(self, x):\n",
    "       animal_pred = self.animal_classifier(x)\n",
    "       sentiment_pred = self.sentiment_classifier(x)\n",
    "       return animal_pred, sentiment_pred\n",
    "\n",
    "# Initialize model and loss function\n",
    "model = AnimalSentimentClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model (quick training on our 3 examples)\n",
    "for epoch in range(100):\n",
    "   optimizer.zero_grad()\n",
    "   animal_pred, sentiment_pred = model(my_embeddings)\n",
    "   \n",
    "   animal_loss = criterion(animal_pred, animal_labels)\n",
    "   sentiment_loss = criterion(sentiment_pred, sentiment_labels)\n",
    "   total_loss = animal_loss + sentiment_loss\n",
    "   \n",
    "   total_loss.backward()\n",
    "   optimizer.step()\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Test function for user input\n",
    "def predict_animal_sentiment(text):\n",
    "   # Convert text to embedding\n",
    "   tokens = tokenizer(text)\n",
    "   token_indices = torch.tensor(vocab(tokens))\n",
    "   text_embedding = embedding_bag(token_indices, offsets=torch.tensor([0]))\n",
    "   \n",
    "   # Make prediction\n",
    "   with torch.no_grad():\n",
    "       animal_pred, sentiment_pred = model(text_embedding.unsqueeze(0))\n",
    "       \n",
    "       animals = ['cats', 'dogs', 'hippos']\n",
    "       sentiments = ['dislike', 'like', 'neutral']\n",
    "       \n",
    "       predicted_animal = animals[torch.argmax(animal_pred).item()]\n",
    "       predicted_sentiment = sentiments[torch.argmax(sentiment_pred).item()]\n",
    "       \n",
    "       print(f\"Text: '{text}'\")\n",
    "       print(f\"Predicted Animal: {predicted_animal}\")\n",
    "       print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
    "       print()\n",
    "\n",
    "# Test with example sentences\n",
    "predict_animal_sentiment(\"I love cats\")\n",
    "predict_animal_sentiment(\"Dogs are terrible\")\n",
    "predict_animal_sentiment(\"Hippos are okay\")\n",
    "predict_animal_sentiment(\"I hate dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f59633-bc3a-4b0c-b8bf-cb846b4ca254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
