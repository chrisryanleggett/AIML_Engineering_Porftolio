{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a367e3-4203-440b-a673-3e378e3350f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INSPECTING PREPARE METHOD ===\n",
      "PREPARE SOURCE CODE:\n",
      "async def prepare(\n",
      "    url: str, path: Optional[str] = None, verbose: bool = True, overwrite: bool = False\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    Prepares a dataset for learners. Downloads a dataset from the given url,\n",
      "    decompresses it if necessary. If not using jupyterlite, will extract to\n",
      "    /tmp and and symlink it so it's available at the desired path.\n",
      "\n",
      "    >>> import skillsnetwork\n",
      "    >>> await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/images.tar.gz\")\n",
      "    Saved to '.'\n",
      "\n",
      "    :param url: The URL to download the dataset from.\n",
      "    :param path: The path the dataset will be available at. Current working directory by default.\n",
      "    :param verbose=True: Prints saved path if True.\n",
      "    :param overwrite=False: If True, overwrites any existing files at destination.\n",
      "    :raise InvalidURLException: When URL is invalid.\n",
      "    :raise FileExistsError: When a file to be symlinked already exists and overwrite is False.\n",
      "    :raise ValueError: When requested path is in /tmp, or cannot be saved to path.\n",
      "    \"\"\"\n",
      "\n",
      "    filename = Path(urlparse(url).path).name\n",
      "    path = Path.cwd() if path is None else Path(path)\n",
      "    # Check if path contains /tmp\n",
      "    if Path(\"/tmp\") in path.parents:\n",
      "        raise ValueError(\"path must not be in /tmp.\")\n",
      "    elif path.is_file():\n",
      "        raise ValueError(\"Datasets must be prepared to directories, not files.\")\n",
      "    # Create the target path if it doesn't exist yet\n",
      "    path.mkdir(exist_ok=True)\n",
      "\n",
      "    # For avoiding collisions with any other files the user may have downloaded to /tmp/\n",
      "    dname = f\"skills-network-{hash(url)}\"\n",
      "    # The file to extract data to. If not jupyterlite, to be symlinked to as well\n",
      "    extract_dir = path if _is_jupyterlite() else Path(f\"/tmp/{dname}\")\n",
      "    # The file to download the (possibly) compressed data to\n",
      "    tmp_download_file = Path(f\"/tmp/{dname}-{filename}\")\n",
      "    # Download the dataset to tmp_download_file file\n",
      "    # File will be overwritten if it already exists\n",
      "    await download(url, tmp_download_file, verbose=False)\n",
      "\n",
      "    # Delete extract_dir directory if it already exists\n",
      "    if not _is_jupyterlite():\n",
      "        if extract_dir.is_dir():\n",
      "            shutil.rmtree(extract_dir)\n",
      "        extract_dir.mkdir()\n",
      "\n",
      "    try:\n",
      "        if tarfile.is_tarfile(tmp_download_file):\n",
      "            with tarfile.open(tmp_download_file) as tf:\n",
      "                _verify_files_dont_exist(\n",
      "                    [\n",
      "                        path / child.name\n",
      "                        for child in map(Path, tf.getnames())\n",
      "                        if len(child.parents) == 1 and _is_file_to_symlink(child)\n",
      "                    ],  # Only check if top-level fileobject\n",
      "                    remove_if_exist=overwrite,\n",
      "                )\n",
      "                pbar = tqdm(iterable=tf.getmembers(), total=len(tf.getmembers()))\n",
      "                pbar.set_description(f\"Extracting {filename}\")\n",
      "                for member in pbar:\n",
      "                    tf.extract(member=member, path=extract_dir)\n",
      "            tmp_download_file.unlink()\n",
      "        elif zipfile.is_zipfile(tmp_download_file):\n",
      "            with zipfile.ZipFile(tmp_download_file) as zf:\n",
      "                _verify_files_dont_exist(\n",
      "                    [\n",
      "                        path / child.name\n",
      "                        for child in map(Path, zf.namelist())\n",
      "                        if len(child.parents) == 1 and _is_file_to_symlink(child)\n",
      "                    ],  # Only check if top-level fileobject\n",
      "                    remove_if_exist=overwrite,\n",
      "                )\n",
      "                pbar = tqdm(iterable=zf.infolist(), total=len(zf.infolist()))\n",
      "                pbar.set_description(f\"Extracting {filename}\")\n",
      "                for member in pbar:\n",
      "                    zf.extract(member=member, path=extract_dir)\n",
      "            tmp_download_file.unlink()\n",
      "        else:\n",
      "            _verify_files_dont_exist([path / filename], remove_if_exist=overwrite)\n",
      "            shutil.move(tmp_download_file, extract_dir / filename)\n",
      "    except FileExistsError as e:\n",
      "        raise FileExistsError(\n",
      "            str(e)\n",
      "            + \"\\nIf you want to overwrite any existing files, use prepare(..., overwrite=True).\"\n",
      "        ) from None\n",
      "\n",
      "    # If in jupyterlite environment, the extract_dir = path, so the files are already there.\n",
      "    if not _is_jupyterlite():\n",
      "        # If not in jupyterlite environment, symlink top-level file objects in extract_dir\n",
      "        for child in filter(_is_file_to_symlink, extract_dir.iterdir()):\n",
      "            if (path / child.name).is_symlink() and overwrite:\n",
      "                (path / child.name).unlink()\n",
      "            (path / child.name).symlink_to(child, target_is_directory=child.is_dir())\n",
      "\n",
      "    if verbose:\n",
      "        print(f\"Saved to '{os.path.relpath(path.resolve())}'\")\n",
      "\n",
      "\n",
      "============================================================\n",
      "FUNCTION SIGNATURE: prepare(url: str, path: Optional[str] = None, verbose: bool = True, overwrite: bool = False) -> None\n",
      "\n",
      "============================================================\n",
      "DOCUMENTATION:\n",
      "\n",
      "    Prepares a dataset for learners. Downloads a dataset from the given url,\n",
      "    decompresses it if necessary. If not using jupyterlite, will extract to\n",
      "    /tmp and and symlink it so it's available at the desired path.\n",
      "\n",
      "    >>> import skillsnetwork\n",
      "    >>> await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/images.tar.gz\")\n",
      "    Saved to '.'\n",
      "\n",
      "    :param url: The URL to download the dataset from.\n",
      "    :param path: The path the dataset will be available at. Current working directory by default.\n",
      "    :param verbose=True: Prints saved path if True.\n",
      "    :param overwrite=False: If True, overwrites any existing files at destination.\n",
      "    :raise InvalidURLException: When URL is invalid.\n",
      "    :raise FileExistsError: When a file to be symlinked already exists and overwrite is False.\n",
      "    :raise ValueError: When requested path is in /tmp, or cannot be saved to path.\n",
      "    \n",
      "\n",
      "=== CHECKING FOR HELPER FUNCTIONS ===\n",
      "Found prepare-related code at line 210:\n",
      "    207:     return b\"\".join([chunk async for chunk in _get_chunks(url, chunk_size)])\n",
      "    208: \n",
      "    209: \n",
      ">>> 210: async def prepare(\n",
      "    211:     url: str, path: Optional[str] = None, verbose: bool = True, overwrite: bool = False\n",
      "    212: ) -> None:\n",
      "    213:     \"\"\"\n",
      "    214:     Prepares a dataset for learners. Downloads a dataset from the given url,\n",
      "    215:     decompresses it if necessary. If not using jupyterlite, will extract to\n",
      "    216:     /tmp and and symlink it so it's available at the desired path.\n",
      "    217: \n",
      "    218:     >>> import skillsnetwork\n",
      "    219:     >>> await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/images.tar.gz\")\n",
      "    220:     Saved to '.'\n",
      "    221: \n",
      "    222:     :param url: The URL to download the dataset from.\n",
      "    223:     :param path: The path the dataset will be available at. Current working directory by default.\n",
      "    224:     :param verbose=True: Prints saved path if True.\n",
      "    225:     :param overwrite=False: If True, overwrites any existing files at destination.\n",
      "    226:     :raise InvalidURLException: When URL is invalid.\n",
      "    227:     :raise FileExistsError: When a file to be symlinked already exists and overwrite is False.\n",
      "    228:     :raise ValueError: When requested path is in /tmp, or cannot be saved to path.\n",
      "    229:     \"\"\"\n",
      "\n",
      "----------------------------------------\n",
      "Found prepare-related code at line 219:\n",
      "    216:     /tmp and and symlink it so it's available at the desired path.\n",
      "    217: \n",
      "    218:     >>> import skillsnetwork\n",
      ">>> 219:     >>> await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/images.tar.gz\")\n",
      "    220:     Saved to '.'\n",
      "    221: \n",
      "    222:     :param url: The URL to download the dataset from.\n",
      "    223:     :param path: The path the dataset will be available at. Current working directory by default.\n",
      "    224:     :param verbose=True: Prints saved path if True.\n",
      "    225:     :param overwrite=False: If True, overwrites any existing files at destination.\n",
      "    226:     :raise InvalidURLException: When URL is invalid.\n",
      "    227:     :raise FileExistsError: When a file to be symlinked already exists and overwrite is False.\n",
      "    228:     :raise ValueError: When requested path is in /tmp, or cannot be saved to path.\n",
      "    229:     \"\"\"\n",
      "    230: \n",
      "    231:     filename = Path(urlparse(url).path).name\n",
      "    232:     path = Path.cwd() if path is None else Path(path)\n",
      "    233:     # Check if path contains /tmp\n",
      "    234:     if Path(\"/tmp\") in path.parents:\n",
      "    235:         raise ValueError(\"path must not be in /tmp.\")\n",
      "    236:     elif path.is_file():\n",
      "    237:         raise ValueError(\"Datasets must be prepared to directories, not files.\")\n",
      "    238:     # Create the target path if it doesn't exist yet\n",
      "\n",
      "----------------------------------------\n",
      "Found prepare-related code at line 294:\n",
      "    291:     except FileExistsError as e:\n",
      "    292:         raise FileExistsError(\n",
      "    293:             str(e)\n",
      ">>> 294:             + \"\\nIf you want to overwrite any existing files, use prepare(..., overwrite=True).\"\n",
      "    295:         ) from None\n",
      "    296: \n",
      "    297:     # If in jupyterlite environment, the extract_dir = path, so the files are already there.\n",
      "    298:     if not _is_jupyterlite():\n",
      "    299:         # If not in jupyterlite environment, symlink top-level file objects in extract_dir\n",
      "    300:         for child in filter(_is_file_to_symlink, extract_dir.iterdir()):\n",
      "    301:             if (path / child.name).is_symlink() and overwrite:\n",
      "    302:                 (path / child.name).unlink()\n",
      "    303:             (path / child.name).symlink_to(child, target_is_directory=child.is_dir())\n",
      "    304: \n",
      "    305:     if verbose:\n",
      "    306:         print(f\"Saved to '{os.path.relpath(path.resolve())}'\")\n",
      "    307: \n",
      "    308: \n",
      "    309: def setup() -> None:\n",
      "    310:     if _is_jupyterlite():\n",
      "    311:         tqdm.monitor_interval = 0\n",
      "    312: \n",
      "    313: \n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "=== CHECKING FOR ARCHIVE FUNCTIONS ===\n",
      "Line 2: import tarfile\n",
      "Line 3: import zipfile\n",
      "\n",
      "=== CHECKING prepare_dataset ===\n",
      "PREPARE_DATASET SOURCE:\n",
      "async def prepare(\n",
      "    url: str, path: Optional[str] = None, verbose: bool = True, overwrite: bool = False\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    Prepares a dataset for learners. Downloads a dataset from the given url,\n",
      "    decompresses it if necessary. If not using jupyterlite, will extract to\n",
      "    /tmp and and symlink it so it's available at the desired path.\n",
      "\n",
      "    >>> import skillsnetwork\n",
      "    >>> await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/images.tar.gz\")\n",
      "    Saved to '.'\n",
      "\n",
      "    :param url: The URL to download the dataset from.\n",
      "    :param path: The path the dataset will be available at. Current working directory by default.\n",
      "    :param verbose=True: Prints saved path if True.\n",
      "    :param overwrite=False: If True, overwrites any existing files at destination.\n",
      "    :raise InvalidURLException: When URL is invalid.\n",
      "    :raise FileExistsError: When a file to be symlinked already exists and overwrite is False.\n",
      "    :raise ValueError: When requested path is in /tmp, or cannot be saved to path.\n",
      "    \"\"\"\n",
      "\n",
      "    filename = Path(urlparse(url).path).name\n",
      "    path = Path.cwd() if path is None else Path(path)\n",
      "    # Check if path contains /tmp\n",
      "    if Path(\"/tmp\") in path.parents:\n",
      "        raise ValueError(\"path must not be in /tmp.\")\n",
      "    elif path.is_file():\n",
      "        raise ValueError(\"Datasets must be prepared to directories, not files.\")\n",
      "    # Create the target path if it doesn't exist yet\n",
      "    path.mkdir(exist_ok=True)\n",
      "\n",
      "    # For avoiding collisions with any other files the user may have downloaded to /tmp/\n",
      "    dname = f\"skills-network-{hash(url)}\"\n",
      "    # The file to extract data to. If not jupyterlite, to be symlinked to as well\n",
      "    extract_dir = path if _is_jupyterlite() else Path(f\"/tmp/{dname}\")\n",
      "    # The file to download the (possibly) compressed data to\n",
      "    tmp_download_file = Path(f\"/tmp/{dname}-{filename}\")\n",
      "    # Download the dataset to tmp_download_file file\n",
      "    # File will be overwritten if it already exists\n",
      "    await download(url, tmp_download_file, verbose=False)\n",
      "\n",
      "    # Delete extract_dir directory if it already exists\n",
      "    if not _is_jupyterlite():\n",
      "        if extract_dir.is_dir():\n",
      "            shutil.rmtree(extract_dir)\n",
      "        extract_dir.mkdir()\n",
      "\n",
      "    try:\n",
      "        if tarfile.is_tarfile(tmp_download_file):\n",
      "            with tarfile.open(tmp_download_file) as tf:\n",
      "                _verify_files_dont_exist(\n",
      "                    [\n",
      "                        path / child.name\n",
      "                        for child in map(Path, tf.getnames())\n",
      "                        if len(child.parents) == 1 and _is_file_to_symlink(child)\n",
      "                    ],  # Only check if top-level fileobject\n",
      "                    remove_if_exist=overwrite,\n",
      "                )\n",
      "                pbar = tqdm(iterable=tf.getmembers(), total=len(tf.getmembers()))\n",
      "                pbar.set_description(f\"Extracting {filename}\")\n",
      "                for member in pbar:\n",
      "                    tf.extract(member=member, path=extract_dir)\n",
      "            tmp_download_file.unlink()\n",
      "        elif zipfile.is_zipfile(tmp_download_file):\n",
      "            with zipfile.ZipFile(tmp_download_file) as zf:\n",
      "                _verify_files_dont_exist(\n",
      "                    [\n",
      "                        path / child.name\n",
      "                        for child in map(Path, zf.namelist())\n",
      "                        if len(child.parents) == 1 and _is_file_to_symlink(child)\n",
      "                    ],  # Only check if top-level fileobject\n",
      "                    remove_if_exist=overwrite,\n",
      "                )\n",
      "                pbar = tqdm(iterable=zf.infolist(), total=len(zf.infolist()))\n",
      "                pbar.set_description(f\"Extracting {filename}\")\n",
      "                for member in pbar:\n",
      "                    zf.extract(member=member, path=extract_dir)\n",
      "            tmp_download_file.unlink()\n",
      "        else:\n",
      "            _verify_files_dont_exist([path / filename], remove_if_exist=overwrite)\n",
      "            shutil.move(tmp_download_file, extract_dir / filename)\n",
      "    except FileExistsError as e:\n",
      "        raise FileExistsError(\n",
      "            str(e)\n",
      "            + \"\\nIf you want to overwrite any existing files, use prepare(..., overwrite=True).\"\n",
      "        ) from None\n",
      "\n",
      "    # If in jupyterlite environment, the extract_dir = path, so the files are already there.\n",
      "    if not _is_jupyterlite():\n",
      "        # If not in jupyterlite environment, symlink top-level file objects in extract_dir\n",
      "        for child in filter(_is_file_to_symlink, extract_dir.iterdir()):\n",
      "            if (path / child.name).is_symlink() and overwrite:\n",
      "                (path / child.name).unlink()\n",
      "            (path / child.name).symlink_to(child, target_is_directory=child.is_dir())\n",
      "\n",
      "    if verbose:\n",
      "        print(f\"Saved to '{os.path.relpath(path.resolve())}'\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE INSPECTION CODE FOR skillsnetwork.prepare()\n",
    "# ============================================================================\n",
    "\n",
    "import skillsnetwork\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "# Step 1: Get the prepare function source code\n",
    "print(\"=== INSPECTING PREPARE METHOD ===\")\n",
    "try:\n",
    "    prepare_source = inspect.getsource(skillsnetwork.prepare)\n",
    "    print(\"PREPARE SOURCE CODE:\")\n",
    "    print(prepare_source)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Get the function signature\n",
    "    sig = inspect.signature(skillsnetwork.prepare)\n",
    "    print(f\"FUNCTION SIGNATURE: prepare{sig}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Get docstring\n",
    "    doc = skillsnetwork.prepare.__doc__\n",
    "    print(\"DOCUMENTATION:\")\n",
    "    print(doc)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not get prepare source: {e}\")\n",
    "\n",
    "# Step 2: Check for any helper functions that prepare() might use\n",
    "print(\"\\n=== CHECKING FOR HELPER FUNCTIONS ===\")\n",
    "\n",
    "# Look in the core.py file for any prepare-related functions\n",
    "core_file = os.path.join(os.path.dirname(skillsnetwork.__file__), 'core.py')\n",
    "\n",
    "with open(core_file, 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Search for prepare-related code\n",
    "lines = content.split('\\n')\n",
    "for i, line in enumerate(lines):\n",
    "    if 'def prepare' in line or 'def _prepare' in line or 'prepare(' in line:\n",
    "        print(f\"Found prepare-related code at line {i+1}:\")\n",
    "        # Show context around the line\n",
    "        start = max(0, i-3)\n",
    "        end = min(len(lines), i+20)\n",
    "        for j in range(start, end):\n",
    "            marker = \">>> \" if j == i else \"    \"\n",
    "            print(f\"{marker}{j+1:3}: {lines[j]}\")\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "\n",
    "# Step 3: Check for any extraction/archive handling functions\n",
    "print(\"\\n=== CHECKING FOR ARCHIVE FUNCTIONS ===\")\n",
    "for i, line in enumerate(lines):\n",
    "    if any(keyword in line.lower() for keyword in ['tar', 'zip', 'extract', 'unpack']):\n",
    "        if 'def ' in line or 'import ' in line:\n",
    "            print(f\"Line {i+1}: {line.strip()}\")\n",
    "\n",
    "# Step 4: Look for prepare_dataset function too\n",
    "print(\"\\n=== CHECKING prepare_dataset ===\")\n",
    "try:\n",
    "    if hasattr(skillsnetwork, 'prepare_dataset'):\n",
    "        prepare_dataset_source = inspect.getsource(skillsnetwork.prepare_dataset)\n",
    "        print(\"PREPARE_DATASET SOURCE:\")\n",
    "        print(prepare_dataset_source)\n",
    "except Exception as e:\n",
    "    print(f\"prepare_dataset inspection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7dd98d-e80f-45a3-b3c1-6e8dd660a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SEARCHING FOR MISSING HELPER FUNCTIONS ===\n",
      "\n",
      "==================== _verify_files_dont_exist ====================\n",
      "Found at line 124:\n",
      "124: def _verify_files_dont_exist(\n",
      "125:     paths: Iterable[Path], remove_if_exist: bool = False\n",
      "126: ) -> None:\n",
      "127:     \"\"\"\n",
      "128:     Verifies all paths in 'paths' don't exist.\n",
      "129:     :param paths: A iterable of pathlib.Path s.\n",
      "130:     :param remove_if_exist=False: Remove each file at each path in paths if they already exist.\n",
      "131:     :returns: None\n",
      "132:     :raises FileExistsError: On the first path found that already exists if remove_if_exist is False.\n",
      "133:     \"\"\"\n",
      "134:     for path in paths:\n",
      "135:         # Could be a broken symlink => path.exists() is False\n",
      "136:         if path.exists() or path.is_symlink():\n",
      "137:             if remove_if_exist:\n",
      "138:                 while path.is_symlink():\n",
      "139:                     temp = Path(os.readlink(path))\n",
      "140:                     path.unlink()\n",
      "141:                     path = temp\n",
      "142:                 if path.exists():\n",
      "143:                     _rmrf(path)\n",
      "144:             else:\n",
      "145:                 raise FileExistsError(f\"Error: File '{path}' already exists.\")\n",
      "146: \n",
      "147: \n",
      "\n",
      "==================== _is_file_to_symlink ====================\n",
      "Found at line 148:\n",
      "148: def _is_file_to_symlink(path: Path) -> bool:\n",
      "149:     \"\"\"\n",
      "150:     :param path: path to check.\n",
      "151:     :returns: True if file should be symlinked, False otherwise.\n",
      "152:     \"\"\"\n",
      "153:     # Don't symlink \"._\" junk\n",
      "154:     return not (path.name.startswith(\"._\") or path.name in [\"__MACOSX\"])\n",
      "155: \n",
      "156: \n",
      "157: async def download(\n",
      "158:     url: str,\n",
      "159:     path: Optional[str] = None,\n",
      "160:     verbose: bool = True,\n",
      "161:     chunk_size: int = DEFAULT_CHUNK_SIZE,\n",
      "162: ) -> None:\n",
      "163:     \"\"\"\n",
      "164:     Downloads file located at URL to path.\n",
      "165: \n",
      "166:     >>> import skillsnetwork\n",
      "167:     >>> path = \"./my_file.txt\"\n",
      "168:     >>> await skillsnetwork.download(\"https://example.com/myfile\", path)\n",
      "169:     Saved as './my_file.txt'\n",
      "170:     >>> with open(path, \"r\") as f:\n",
      "171:     >>>     content = f.read()\n",
      "172: \n",
      "173:     :param url: The URL where the file is located.\n",
      "174:     :param path: The path to which the file at URL should be downloaded. Auto-generated from url by default.\n",
      "175:     :param chunk_size: The number of bytes to read from url at a time.\n",
      "176:     :raise FileNotFoundError: If path is invalid.\n",
      "177:     :raise skillsnetwork.InvalidURLException: If URL is invalid.\n",
      "178:     \"\"\"\n",
      "179:     filename = Path(urlparse(url).path).name\n",
      "180:     if path is None:\n",
      "181:         path = Path.cwd() / filename\n",
      "182:     else:\n",
      "183:         path = Path(path)\n",
      "184:         if path.is_dir():\n",
      "185:             path /= filename\n",
      "186:     with open(path, \"wb\") as f:  # Will raise FileNotFoundError if invalid path\n",
      "187:         async for chunk in _get_chunks(url, chunk_size):\n",
      "188:             f.write(chunk)\n",
      "189:     if verbose:\n",
      "190:         print(f\"Saved as '{os.path.relpath(path.resolve())}'\")\n",
      "191: \n",
      "192: \n",
      "193: async def read(url: str, chunk_size: int = DEFAULT_CHUNK_SIZE) -> bytes:\n",
      "194:     \"\"\"\n",
      "195:     Reads file at URL into bytes\n",
      "196: \n",
      "197:     >>> import skillsnetwork\n",
      "198:     >>> content = await skillsnetwork.read(\"https://example.com/myfile\") # Is bytes\n",
      "199:     >>> content_str = content.decode()                                   # Is str\n",
      "200: \n",
      "201:     :param url: The URL where the file is located.\n",
      "202:     :param chunk_size: Number of bytes to read from url at a time.\n",
      "203:     :returns: bytes containing file located at URL\n",
      "204:     :raise FileNotFoundError: If path is invalid.\n",
      "205:     :raise InvalidURLException: If URL is invalid.\n",
      "206:     \"\"\"\n",
      "207:     return b\"\".join([chunk async for chunk in _get_chunks(url, chunk_size)])\n",
      "208: \n",
      "209: \n",
      "210: async def prepare(\n",
      "211:     url: str, path: Optional[str] = None, verbose: bool = True, overwrite: bool = False\n",
      "212: ) -> None:\n",
      "213:     \"\"\"\n",
      "214:     Prepares a dataset for learners. Downloads a dataset from the given url,\n",
      "215:     decompresses it if necessary. If not using jupyterlite, will extract to\n",
      "216:     /tmp and and symlink it so it's available at the desired path.\n",
      "217: \n",
      "218:     >>> import skillsnetwork\n",
      "219:     >>> await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/images.tar.gz\")\n",
      "220:     Saved to '.'\n",
      "221: \n",
      "222:     :param url: The URL to download the dataset from.\n",
      "223:     :param path: The path the dataset will be available at. Current working directory by default.\n",
      "224:     :param verbose=True: Prints saved path if True.\n",
      "225:     :param overwrite=False: If True, overwrites any existing files at destination.\n",
      "226:     :raise InvalidURLException: When URL is invalid.\n",
      "227:     :raise FileExistsError: When a file to be symlinked already exists and overwrite is False.\n",
      "228:     :raise ValueError: When requested path is in /tmp, or cannot be saved to path.\n",
      "229:     \"\"\"\n",
      "230: \n",
      "231:     filename = Path(urlparse(url).path).name\n",
      "232:     path = Path.cwd() if path is None else Path(path)\n",
      "233:     # Check if path contains /tmp\n",
      "234:     if Path(\"/tmp\") in path.parents:\n",
      "235:         raise ValueError(\"path must not be in /tmp.\")\n",
      "236:     elif path.is_file():\n",
      "237:         raise ValueError(\"Datasets must be prepared to directories, not files.\")\n",
      "238:     # Create the target path if it doesn't exist yet\n",
      "239:     path.mkdir(exist_ok=True)\n",
      "240: \n",
      "241:     # For avoiding collisions with any other files the user may have downloaded to /tmp/\n",
      "242:     dname = f\"skills-network-{hash(url)}\"\n",
      "243:     # The file to extract data to. If not jupyterlite, to be symlinked to as well\n",
      "244:     extract_dir = path if _is_jupyterlite() else Path(f\"/tmp/{dname}\")\n",
      "245:     # The file to download the (possibly) compressed data to\n",
      "246:     tmp_download_file = Path(f\"/tmp/{dname}-{filename}\")\n",
      "247:     # Download the dataset to tmp_download_file file\n",
      "248:     # File will be overwritten if it already exists\n",
      "249:     await download(url, tmp_download_file, verbose=False)\n",
      "250: \n",
      "251:     # Delete extract_dir directory if it already exists\n",
      "252:     if not _is_jupyterlite():\n",
      "253:         if extract_dir.is_dir():\n",
      "254:             shutil.rmtree(extract_dir)\n",
      "255:         extract_dir.mkdir()\n",
      "256: \n",
      "257:     try:\n",
      "258:         if tarfile.is_tarfile(tmp_download_file):\n",
      "259:             with tarfile.open(tmp_download_file) as tf:\n",
      "260:                 _verify_files_dont_exist(\n",
      "261:                     [\n",
      "262:                         path / child.name\n",
      "263:                         for child in map(Path, tf.getnames())\n",
      "264:                         if len(child.parents) == 1 and _is_file_to_symlink(child)\n",
      "265:                     ],  # Only check if top-level fileobject\n",
      "266:                     remove_if_exist=overwrite,\n",
      "267:                 )\n",
      "268:                 pbar = tqdm(iterable=tf.getmembers(), total=len(tf.getmembers()))\n",
      "269:                 pbar.set_description(f\"Extracting {filename}\")\n",
      "270:                 for member in pbar:\n",
      "271:                     tf.extract(member=member, path=extract_dir)\n",
      "272:             tmp_download_file.unlink()\n",
      "273:         elif zipfile.is_zipfile(tmp_download_file):\n",
      "274:             with zipfile.ZipFile(tmp_download_file) as zf:\n",
      "275:                 _verify_files_dont_exist(\n",
      "276:                     [\n",
      "277:                         path / child.name\n",
      "278:                         for child in map(Path, zf.namelist())\n",
      "279:                         if len(child.parents) == 1 and _is_file_to_symlink(child)\n",
      "280:                     ],  # Only check if top-level fileobject\n",
      "281:                     remove_if_exist=overwrite,\n",
      "282:                 )\n",
      "283:                 pbar = tqdm(iterable=zf.infolist(), total=len(zf.infolist()))\n",
      "284:                 pbar.set_description(f\"Extracting {filename}\")\n",
      "285:                 for member in pbar:\n",
      "286:                     zf.extract(member=member, path=extract_dir)\n",
      "287:             tmp_download_file.unlink()\n",
      "288:         else:\n",
      "289:             _verify_files_dont_exist([path / filename], remove_if_exist=overwrite)\n",
      "290:             shutil.move(tmp_download_file, extract_dir / filename)\n",
      "291:     except FileExistsError as e:\n",
      "292:         raise FileExistsError(\n",
      "293:             str(e)\n",
      "294:             + \"\\nIf you want to overwrite any existing files, use prepare(..., overwrite=True).\"\n",
      "295:         ) from None\n",
      "296: \n",
      "297:     # If in jupyterlite environment, the extract_dir = path, so the files are already there.\n",
      "298:     if not _is_jupyterlite():\n",
      "299:         # If not in jupyterlite environment, symlink top-level file objects in extract_dir\n",
      "300:         for child in filter(_is_file_to_symlink, extract_dir.iterdir()):\n",
      "301:             if (path / child.name).is_symlink() and overwrite:\n",
      "302:                 (path / child.name).unlink()\n",
      "303:             (path / child.name).symlink_to(child, target_is_directory=child.is_dir())\n",
      "304: \n",
      "305:     if verbose:\n",
      "306:         print(f\"Saved to '{os.path.relpath(path.resolve())}'\")\n",
      "307: \n",
      "308: \n",
      "\n",
      "==================== IMPORTS NEEDED ====================\n",
      "  1: import shutil\n",
      "  2: import tarfile\n",
      "  3: import zipfile\n",
      "  4: import IPython\n",
      "  5: import os\n",
      "  7: from pathlib import Path\n",
      "  8: from urllib.parse import urlparse\n",
      "  9: from typing import List, Union, Optional, Iterable, Generator\n",
      " 10: from tqdm.auto import tqdm\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# GET THE MISSING HELPER FUNCTIONS FOR prepare()\n",
    "# ============================================================================\n",
    "\n",
    "import skillsnetwork\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "# The prepare() function uses these helper functions we need to find:\n",
    "missing_functions = ['_verify_files_dont_exist', '_is_file_to_symlink']\n",
    "\n",
    "print(\"=== SEARCHING FOR MISSING HELPER FUNCTIONS ===\")\n",
    "\n",
    "# Read the entire core.py file and search for these functions\n",
    "core_file = os.path.join(os.path.dirname(skillsnetwork.__file__), 'core.py')\n",
    "\n",
    "with open(core_file, 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "lines = content.split('\\n')\n",
    "\n",
    "for func_name in missing_functions:\n",
    "    print(f\"\\n{'='*20} {func_name} {'='*20}\")\n",
    "    found = False\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if f'def {func_name}' in line:\n",
    "            found = True\n",
    "            print(f\"Found at line {i+1}:\")\n",
    "            \n",
    "            # Get the complete function (until next function or end)\n",
    "            start = i\n",
    "            indent_level = len(line) - len(line.lstrip())\n",
    "            \n",
    "            # Find the end of this function\n",
    "            end = len(lines)\n",
    "            for j in range(i+1, len(lines)):\n",
    "                current_line = lines[j]\n",
    "                if current_line.strip() and len(current_line) - len(current_line.lstrip()) <= indent_level:\n",
    "                    if current_line.strip().startswith('def ') or current_line.strip().startswith('class '):\n",
    "                        end = j\n",
    "                        break\n",
    "            \n",
    "            # Print the complete function\n",
    "            for k in range(start, end):\n",
    "                print(f\"{k+1:3}: {lines[k]}\")\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"❌ {func_name} not found in core.py\")\n",
    "\n",
    "# Also check what imports are needed at the top\n",
    "print(f\"\\n{'='*20} IMPORTS NEEDED {'='*20}\")\n",
    "for i, line in enumerate(lines[:30]):  # Check first 30 lines for imports\n",
    "    if line.strip().startswith('import ') or line.strip().startswith('from '):\n",
    "        print(f\"{i+1:3}: {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841f7394-bb11-4b5b-b73c-17c6807dfacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SEARCHING FOR _rmrf FUNCTION ===\n",
      "Found at line 117:\n",
      "117: def _rmrf(path: Path) -> None:\n",
      "118:     if path.is_dir():\n",
      "119:         shutil.rmtree(path)\n",
      "120:     else:\n",
      "121:         path.unlink()\n",
      "122: \n",
      "123: \n"
     ]
    }
   ],
   "source": [
    "# Find the _rmrf function\n",
    "import skillsnetwork\n",
    "import os\n",
    "\n",
    "core_file = os.path.join(os.path.dirname(skillsnetwork.__file__), 'core.py')\n",
    "\n",
    "with open(core_file, 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "lines = content.split('\\n')\n",
    "\n",
    "print(\"=== SEARCHING FOR _rmrf FUNCTION ===\")\n",
    "for i, line in enumerate(lines):\n",
    "    if 'def _rmrf' in line:\n",
    "        print(f\"Found at line {i+1}:\")\n",
    "        # Get the complete function\n",
    "        start = i\n",
    "        indent_level = len(line) - len(line.lstrip())\n",
    "        \n",
    "        # Find end of function\n",
    "        end = len(lines)\n",
    "        for j in range(i+1, len(lines)):\n",
    "            current_line = lines[j]\n",
    "            if current_line.strip() and len(current_line) - len(current_line.lstrip()) <= indent_level:\n",
    "                if current_line.strip().startswith('def ') or current_line.strip().startswith('class '):\n",
    "                    end = j\n",
    "                    break\n",
    "        \n",
    "        # Print the function\n",
    "        for k in range(start, end):\n",
    "            print(f\"{k+1:3}: {lines[k]}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc29b8-be55-4ae0-b728-4b3cd411cc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
